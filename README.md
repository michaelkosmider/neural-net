Welcome to my neural network project. The implementation is written entirely from scratch using Python and NumPy, including all of the functions and calculations used in gradient descent. This project showcases my abilities in calculus, linear algebra and manipulation of NumPy arrays. 

Users can specify model hyperparameters such as the shape of the neural network (number and width of layers), type of activation function, learning rate, number of epochs (how long to train the model for), batch size and regularization constant.

Check out the demo notebook to see how it works! 
